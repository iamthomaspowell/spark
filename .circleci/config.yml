version: 2
jobs:
  build:
    working_directory: ~/spark
    docker:
      - image: docker:1.13.1-git
      # - image: circleci/build-image:ubuntu-14.04-XL-922-9410082
      # - image: continuumio/miniconda3:4.3.11
    steps:
      - checkout
      # - run:
      #   name: Install Docker client
      #   command: |
      #     set -x
      #     VER="17.03.0-ce"
      #     curl -L -o /tmp/docker-$VER.tgz https://get.docker.com/builds/Linux/x86_64/docker-$VER.tgz
      #     tar -xz -C /tmp -f /tmp/docker-$VER.tgz
      #     mv /tmp/docker/* /usr/bin
      - setup_docker_engine
      - run:
          name: Install Docker Compose
          command: |
            set -x
            curl -L https://github.com/docker/compose/releases/download/1.11.2/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose
            chmod +x /usr/local/bin/docker-compose
      - run: |
          docker build -t spark .
      - run: |
          docker-compose up -d
      - run:
          name: Create Conda Environments
          command: |
            docker exec spark bash <<"EOF"
              set -x
              $CONDA_BIN create -y -n python2 python==2.7.11 numpy
              $CONDA_BIN create -y -n python3 python==3.4.4 numpy
              pyenv global python2 python3 #pypy-4.0.1
            EOF
